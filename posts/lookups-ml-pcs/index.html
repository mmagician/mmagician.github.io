<!doctype html><html lang=en-us><head><link rel=preload href=../../lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=../../lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=../../lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=../../lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Need for Speed: efficient multilinear PCS in Lasso and Jolt | Hungry Cats Studio</title>
<link rel=canonical href=https://HungryCatsStudio.github.io/posts/lookups-ml-pcs/><meta name=description content="Hungry Cats and blogs."><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="Need for Speed: efficient multilinear PCS in Lasso and Jolt"><meta property="og:description" content="Problem statement In this write-up, we aim to provide context for the Need for Speed: why do we need efficient (multilinear) polynomial commitment schemes for lookups, specifically in the context of Lasso and Jolt.
To put the problem into context, we first motivate the need for Lasso, and lookups in general, with an example. We then briefly describe the non-trivial marriage of lookup arguments with general SNARKs for R1CS. To complete the big picture, we provide a short introduction to Lasso’s solution to lookups - and where exactly the polynomial commitment schemes come up."><meta property="og:type" content="article"><meta property="og:url" content="https://HungryCatsStudio.github.io/posts/lookups-ml-pcs/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-20T11:03:00+02:00"><meta property="article:modified_time" content="2023-10-20T11:03:00+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Need for Speed: efficient multilinear PCS in Lasso and Jolt"><meta name=twitter:description content="Problem statement In this write-up, we aim to provide context for the Need for Speed: why do we need efficient (multilinear) polynomial commitment schemes for lookups, specifically in the context of Lasso and Jolt.
To put the problem into context, we first motivate the need for Lasso, and lookups in general, with an example. We then briefly describe the non-trivial marriage of lookup arguments with general SNARKs for R1CS. To complete the big picture, we provide a short introduction to Lasso’s solution to lookups - and where exactly the polynomial commitment schemes come up."><link rel=stylesheet href=https://HungryCatsStudio.github.io/css/styles.94f653e9e151e28067a7c5dbbc4600cbd5a3c721e79faaf971e523c40f3b249b8e4f20bb57810dfffa8d559ca5c140fd56eb4cd9c0853113ad08e66afdb08bdd.css integrity="sha512-lPZT6eFR4oBnp8XbvEYAy9WjxyHnn6r5ceUjxA87JJuOTyC7V4EN//qNVZylwUD9VutM2cCFMROtCOZq/bCL3Q=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://HungryCatsStudio.github.io/images/favicon.ico><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=../../>Home</a></li><li><a href=../../about>About</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://HungryCatsStudio.github.io/posts/non-native/ aria-label=Previous><i class="fas fa-chevron-left" aria-hidden=true onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&text=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&is_video=false&description=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt&body=Check out this article: https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&name=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt&description=Problem%20statement%20In%20this%20write-up%2c%20we%20aim%20to%20provide%20context%20for%20the%20Need%20for%20Speed%3a%20why%20do%20we%20need%20efficient%20%28multilinear%29%20polynomial%20commitment%20schemes%20for%20lookups%2c%20specifically%20in%20the%20context%20of%20Lasso%20and%20Jolt.%0aTo%20put%20the%20problem%20into%20context%2c%20we%20first%20motivate%20the%20need%20for%20Lasso%2c%20and%20lookups%20in%20general%2c%20with%20an%20example.%20We%20then%20briefly%20describe%20the%20non-trivial%20marriage%20of%20lookup%20arguments%20with%20general%20SNARKs%20for%20R1CS.%20To%20complete%20the%20big%20picture%2c%20we%20provide%20a%20short%20introduction%20to%20Lasso%e2%80%99s%20solution%20to%20lookups%20-%20and%20where%20exactly%20the%20polynomial%20commitment%20schemes%20come%20up." aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&t=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#lasso-overview>Lasso overview</a><ul><li><a href=#motivation-for-lookups>Motivation for lookups</a></li><li><a href=#enter-the-lookup-table>Enter the lookup (table)</a></li><li><a href=#lasso-in-a-nutshell>Lasso in a nutshell</a></li><li><a href=#idk-how-it-works-but-i-know-why-its-expensive>IDK how it works, but I know why it’s expensive,</a></li></ul></li><li><a href=#what-should-i-aim-for>What should I aim for?</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Need for Speed: efficient multilinear PCS in Lasso and Jolt</h1><div class=meta><div class=postdate><time datetime="2023-10-20 11:03:00 +0200 +0200" itemprop=datePublished>20-10-2023</time></div><div class=article-read-time><i class="far fa-clock"></i>
13 minute read</div></div></header><div class=content itemprop=articleBody><h1 id=problem-statement>Problem statement</h1><p>In this write-up, we aim to provide context for the Need for Speed: why do we need efficient (multilinear) polynomial commitment schemes for lookups, specifically in the context of Lasso and Jolt.</p><p>To put the problem into context, we first motivate the need for Lasso, and lookups in general, with an example. We then briefly describe the non-trivial marriage of lookup arguments with general SNARKs for R1CS. To complete the big picture, we provide a short introduction to Lasso’s solution to lookups - and where exactly the polynomial commitment schemes come up.</p><p>In a follow-up post, we will present the actual results benchmarking 4 PC schemes implemented with an arkworks backend: Ligero, Brakedown, Hyrax
and KZG.</p><h2 id=lasso-overview>Lasso overview</h2><p>In summary, Lasso is a lookup argument (family). It lets the prover commit to a vector of $m$ field elements and prove that they reside in some predetermined table $t$ of $n$ elements. How should we think about this vector and table, though? What do they really represent?</p><h3 id=motivation-for-lookups>Motivation for lookups</h3><p>First, we need to put Lasso, or lookup arguments in general, into some context. Suppose the prover has a long and complex program that he wishes to prove a correct execution of. A natural step would be to arithmetize this computation (e.g. using R1CS) and later use some off-the-shelf SNARK to succinctly generate a proof. The problem with this naive approach is that real-world computation rarely operates on finite field elements as required by R1CS - instead, the program makes use of CPU friendly types, such as the 64-bit integers, to construct some complex computation.</p><p>This leads to a mismatch of representations and our arithmetization needs to account for this: otherwise the arithmetic circuit gives extra adversarial power to the prover by letting him “wrap around” the field modulus. Consider e.g. the simple program:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-latex data-lang=latex><span style=display:flex><span>x^2 = y
</span></span></code></pre></div><p>Where <code>x</code> is the witness and <code>y</code> is the public instance. We convert it to a R1CS instance:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-latex data-lang=latex><span style=display:flex><span>A = [0 1 0]; B = [0 1 0]; C = [0 0 1];    z = [1 x y]^T
</span></span></code></pre></div><p>The prover wants to convince the verifier that he knows a satisfying assignment to <code>z</code> such that $A\cdot z \odot B \cdot z = C \cdot z$ for a partially known <code>z = [1 x 25]</code>, say. By inspection we see that <code>x = 5</code>, but since we’re working with finite fields, there could be two solutions: the answer could also be $p - 5$, for a field modulus $p$. More precisely, a unique solution in the natural numbers (here, unsigned integers) is not &ldquo;supported&rdquo; with this relation over fields.</p><p>The way to circumvent this issue is to introduce restrictions on the bit decomposition of <code>x</code>: constrain every bit to be either 0 or 1 (duh!), and require the weighted sum of all bits by suitable powers of two to equal $x$. To constrain each bit <code>x_i</code> of the <strong>field element</strong> <code>x</code> we impose the restriction that $x_i^2 = x_i$. These two conditions asssure that $x$ fits in the prescribed number of bits (e.g. 64) and we have a unique solution.</p><p>In R1CS language, this would look something like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-latex data-lang=latex><span style=display:flex><span>z = 
</span></span><span style=display:flex><span>[1  x  x_0 x_1 x_2 ... x_63   y]^T
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>A = 
</span></span><span style=display:flex><span>[0  1  0   0   0  ...   0     0] // for x^2 = y
</span></span><span style=display:flex><span>[0  0  1   0   0  ...   0     0] // for x_0^2 = x_0
</span></span><span style=display:flex><span>[0  0  0   1   0  ...   0     0] // for x_1^2 = x_1
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>[0  0  0   0   0  ...   1     0] // for x_63^2 = x_64
</span></span><span style=display:flex><span>[0  0  1   2   4  ...   2^63  0] // for x_0 + 2*x_1 + ...  2^63*x_63 = x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>B = 
</span></span><span style=display:flex><span>[0  1  0   0   0  ...   0     0] // for x^2 = y, same as A
</span></span><span style=display:flex><span>[0  0  1   0   0  ...   0     0] // for x_0^2 = x_0, same as A
</span></span><span style=display:flex><span>[0  0  0   1   0  ...   0     0] // for x_1^2 = x_1, same as A
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>[0  0  0   0   0  ...   1     0] // for x_63^2 = x_63, same as A
</span></span><span style=display:flex><span>[1  0  0   0   0  ...   0     0] // for x_0 + 2*x_1 + ...  2^63*x_63 = x, different!
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>C = 
</span></span><span style=display:flex><span>[0  0  0   0   0  ...   0     1] // for x^2 = y
</span></span><span style=display:flex><span>[0  0  1   0   0  ...   0     0] // for x_0^2 = x_0
</span></span><span style=display:flex><span>[0  0  0   1   0  ...   0     0] // for x_1^2 = x_1
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>[0  0  0   0   0  ...   1     0] // for x_63^2 = x_63
</span></span><span style=display:flex><span>[0  1  0   0   0  ...   0     0] // for x_0 + 2*x_1 + ...  2^63*x_63 = x
</span></span></code></pre></div><p>We’ve now assured the verifier that we have a valid solution to <code>x^2 = y</code> AND that <code>x</code> is small (fits into 64 bits). This carries a massive overhead, though: for every element <code>x</code> in our program that is not naturally a field element, such as <code>u64</code>, we need to add $64 + 1$ additional constraints to convince the verifier of its bit decomposition.</p><p>Can we do better?</p><h3 id=enter-the-lookup-table>Enter the lookup (table)</h3><p>The motivating question is then: could we use lookups instead of bit decomposition?</p><p>Lookup arguments phrase the question as following:</p><p>Suppose we want to prove that a variable in the computation is within the range $[0, 2^{64})$. Can we show that it is one of the values in some publicly known table $t$, whose entries are all the integers between $0$ and $2^{64} - 1$?</p><p>There has been a line of work exploring different techniques as well as trade-offs for achieving that goal. These have led to lookup arguments: protocols for convincing the verifier that one or more committed elements reside in some publicly known table $t$.</p><p>However, it is not immediately clear how to combine a lookup argument with a general SNARK, since they represent fundamentally different relations. The statement proved in a SNARK is about arithmetic circuit satisfiability, whereas a prover in a lookup argument convinces the verifier that all elements in a committed vector reside in a public table.</p><p>We’ve seen some SNARKs utilizing the Plonk-ish arithmetization that have integrated a lookup into the relation, but it doesn’t seem to translate directly to SNARKs based on R1CS arithmetization. <a href=https://ethresear.ch/t/grolup-plookup-for-r1cs/14307>This blog post</a> explores a potential idea borrowed from LegoSNARK for adding Plookup to Groth16.</p><p>The key insight there is that we can combine two different arguments (e.g. for different parts of our computation) if they have an explicit (and similarly structured) commitment to the same witness - which is not the case e.g. for Groth16, where the proof contains the committed witness only implicitly.</p><p>In the case of Jolt, the commitment used in the lookup is actually a subset of the commitment used for proving general circuit satisfiability. Think back to the previous example where the witness consisted of 65 elements: <code>w = [x x_0 x_2 ... x_63]</code>: now by strapping a lookup onto our SNARK, we can forego the long witness and keep just <code>w = [x]</code>. Aside from a shorter witness, we have immediately reduced the overhead in terms of number of constraints by discarding all the binary decomposition checks. Instead, to prove that $x$ fits into 64 bits we use a lookup argument into a giant-but-highly-structured table of $2^{64}$ elements.</p><p>Note that in our trivial relation, the commitment to the vector used in the lookup, $x$, is the same as the commitment of the entire R1CS witness. In general this won&rsquo;t be the case and we would need to identify the subset of the R1CS witness that is going to be used in the lookup argument.</p><p>For example, for a witness $w$ of length $2n$ (for simplicity, assume $n$ is a power of two), imagine that only the first $n$ R1CS variables are part of the lookup argument.</p><p>Without diverging into the details, we state that the SNARK employed here to reason about R1CS satisfiability is <a href=https://eprint.iacr.org/2019/550>Spartan</a>. The Spartan prover low-degree extends the witness and then commits to that polynomial.</p><p>With the perspective of adding a lookup argument, rather than committing to the MLE of the entire witness vector $\widetilde{w}$ directly, notice that:
$$\widetilde{w}(x_1, &mldr;, x_{\log(n)+1}) = (1-x_1) \times \widetilde{w_1}(x_2, &mldr;, x_{\log(n) + 1}) + x_1 \times \widetilde{w_2}(x_2, &mldr;, x_{\log(n) + 1})$$</p><p>So instead of committing to $\widetilde{w}$, we can split the witness in two halves and commit to their MLEs separately: first to $\widetilde{w_1}(x_1, &mldr;, x_{\log(n)})$, then to $\widetilde{w_2}(x_1, &mldr;, x_{\log(n)})$. By the above relation, and for homomorphic commitments, the verifier can easily obtain the commitment to the full $w$ by himself, and later query the committed $w$ by asking for the opening of both $\widetilde{w_1}$ and $\widetilde{w_2}$ (at the same point) and combining the result.</p><p>This technique enables us to use one argument (e.g. SNARK) on the entirety of the committed witness and another argument (e.g. a lookup argument) on a subset of the committed elements - while maintaining a link between the two parts.</p><p>We have so far only given an intuition for where lookups would be useful and how to integrate them into an R1CS-arithmetized “multilinear SNARK”. We have intentionally skipped the details of how lookups actually work. In fact, Lasso mechanics differ substantially from most of the existing lookup arguments and so we will not cover these. For an excellent overview of the literature <a href=https://github.com/ingonyama-zk/papers/blob/main/lookups.pdf>“A Brief History of Lookup Arguments”</a>.</p><h3 id=lasso-in-a-nutshell>Lasso in a nutshell</h3><p>The Lasso verifier seeks to confirm that the relationship $M \cdot t = a$ holds, where:</p><ul><li>$t$ is a large lookup table with some “good” structure, of size $N$,</li><li>$a$ is the vector of elements to be looked up. If we want to perform $m$ lookups in our protocol, then $a$ has size $m$.</li><li>$M$ is the $m \times N$ matrix whose rows are unit vectors in such a way as to make the above true if and only if all entries of $a$ are contained in $t$. Such a matrix always has exactly one non-zero entry per row. Indeed, if the i-th entry of $t$ is the j-th element of $a$, then the j-th row of $M$ is a one-hot vector concentrated in its i-th entry.</li></ul><p>To give a tiny example, set: $m = 2$, $N = 4$. The prover wants to show that all elements of $a = (1, 3)$ are within the range $[0, 4)$ - i.e. they are contained in the table $(0, 1, 2, 3)$.</p><p>Then a satisfying assignment would be:</p><p>$$\begin{pmatrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1\end{pmatrix} \cdot \begin{pmatrix} 0 \\ 1 \\ 2 \\ 3\end{pmatrix} = \begin{pmatrix} 1 \\ 3 \end{pmatrix} $$</p><p>Typically, in our succinct protocol the (low-degree extensions of the) matrices $a$ and $M$ are committed to and the verifier is only given oracle access to them, with the oracle instantiated via a polynomial commitment scheme. We assume that $t$ has some “nice” structural properties to allow the verifier to efficiently work with it, as described later.</p><p>Unlike in our tiny example, $m$ is often <strong>much</strong> smaller than $N$: $m \ll N$.</p><p>So committing to $a$ can be feasible, but notice that the number of entries of $M$ is actually larger by a factor of $m$ than the number of entries of the lookup table. If we want to use humongous lookup tables in our protocol (think $2^{128}$) then we certainly can’t allow ourselves to commit to that many elements of $M$.</p><p>Instead, we leverage the following fact: most of the entries in $M$ are $0$ (the matrix is sparse). More precisely, we won’t be committing to a matrix per se - rather, to its multilinear extension (MLE) (for more details on how to transform any function to low-degree extensions, see Sec. 3.5 of the <a href=https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.pdf>Proofs, Args and Zero-Knowledge</a> survey by J. Thaler). Furthermore, rather than checking that the statement $M \cdot t = a$ holds for all entries of $a$, we pick a random point $r \in \mathbb{F}^{\log(m)}$ and, if the equality below holds for $r$, then the original statement holds with high probability:</p><p>$$
\sum_{j \in \{0,1\}^{\log(N)}} \widetilde {M}(r, j) \cdot \widetilde t(j) = \widetilde{a}(r),
$$</p><p>where $M(x, y)$ is the function that maps indices x, y, represented as bits, to the entry $M_{x, y}$.</p><p>Finally, a quick note on the table $t$: we assume that $t$ has enough structure for the verifier to efficiently evaluate it at any single point. Since the above equation is begging to be sumchecked, at the conclusion of the sumcheck protocol we require the verifier to only query the MLE of the table $\widetilde{t}$ at one single point $r’$. Details of how $t$’s structure lends itself to efficient evaluation are not necessary for our objective here and can be found directly in the Lasso paper.</p><p>Therefore, we have established that in order to prove membership of all elements of $a$ in a lookup table $t$, Lasso needs a way to efficiently commit to a very large-but-sparse matrix $M$.</p><h3 id=idk-how-it-works-but-i-know-why-its-expensive>IDK how it works, but I know why it’s expensive,</h3><p>…or glossing over Spark & Surge.</p><p>Spark is a way to commit to sparse multilinear polynomials with the prover costs proportional to the number of non-zero evaluation over the boolean hypercube, rather than to the size of the hypercube itself, as would be the case for dense polynomials. The approach of Spark is to commit to such a sparse vector of evaluations, and later prove the correct computation of its dot product with the Lagrange basis evaluated at the random point queried by the verifier.</p><p>We view any multilinear polynomial’s $\widetilde f$ over $v$ variables as:</p><p>$$
\widetilde{f}(x_1, &mldr;, x_v) = \sum_{w \in \{0,1\}^v} f(w) \cdot \chi_w(x_1, &mldr;, x_v)
$$</p><p>With $f(w)$ being the evaluations over the Boolean hypercube, and $\chi_w(x_1,…x_v)$ the multilinear Lagrange basis polynomial corresponding to $w$.</p><p>We are already given $f(w)$ as part of the description of the multilinear polynomial.</p><p>Therefore, if we can somehow evaluate $\chi_w(r_1,…r_v)$ efficiently for all $w \in \{0,1\}^v$, then we are in a good position to compute the dot product. It turns out that exists an efficient procedure to do this.</p><p>The authors of Lasso notice that Spark can be generalized to prove inner products for other purposes than just opening a polynomial at a random point.</p><p>Surge is such a generalization, which replaces the Lagrange basis in above equation with any function efficiently evaluateable at any $w$, specifically with the function $t(w)$ that maps any index $w$ to an element of our table.</p><p>The way that Spark and Surge prove this relationship holds is by leveraging an adaptation of a technique called offline memory checking. Here is where we disappoint the reader and instead refer them to Sec. 5 of Lasso, where the scheme is described in a very accessible manner.</p><p>Instead, we simply summarize the costs in the full realization of offline memory checking when applied to Lasso. Since “pure” field operations are at least an order of magnitude faster than cryptographic operations involved in committing to the polynomials, we omit the former.</p><p><strong><strong><strong><strong><strong><strong>Prover:</strong></strong></strong></strong></strong></strong></p><ul><li>Commit to $c$ polynomials over $\log(m)$ variables</li><li>Commit to $2\cdot \alpha$ polynomials over $\log(m)$ variables</li><li>Commit to $\alpha$ polynomials over $\log(N^{1/c})$ variables</li><li>Prove openings of $\alpha$ $\log(m)$-variate polynomials, all at one point $r_z$</li><li>Prove openings of $3$ $\log(m)$-variate and one $\log(N^{1/c})$-variate polynomials, all at one point $r_b$ (after batching sumchecks)</li></ul><p><strong><strong><strong><strong><strong><strong><strong><strong><strong>Verifier</strong></strong></strong></strong></strong></strong></strong></strong></strong></p><ul><li>Verify the corresponding openings</li></ul><p>Here $c$ is a parameter we choose freely and $\alpha = c \cdot k$ for a small constant $k$. We recall that $N$ is the size of the table and $m$ is the number of lookups.</p><p>Since our objective is to pick the best candidate for Jolt, let’s focus on its flagship application, emulation of RISC-V ISA over the 64-bit data types. A reasonable parameter choice there is $c = 6$ and $N = 2^{128}$. The bottleneck for the prover is then committing to polynomials over ~20 variables. This is what we target in our benchmarks.</p><p>We also note that most of the committed elements are “small”, in the sense that they can be represented by field elements of size, say $\lt 2^{64}$. Some PC schemes can take advantage of this, including KZG and Hyrax, where the critical component of the scheme is the multi-scalar exponentiation, which naturally favors smaller exponents.</p><p>Armed with all this knowledge, we are now ready to pick the best PCS candidate. Almost.</p><h2 id=what-should-i-aim-for>What should I aim for?</h2><p>As with everything, it depends. Some possible targets are:</p><ul><li>Prover time</li><li>Verifier time</li><li>Proof size</li><li>On-chain verification</li><li>Recursion friendliness</li></ul><p>Context choice will play an important role here. For the use cases where we care about on-chain verification, we need to be mindful of gas costs associated with the verification, as well as proof sizes that we upload. Optimizing for verifier speed will often incur additional prover complexity, which might become prohibitive for large computation. For big enough programs, proof composition might bridge this gap.</p><p>In the next post we will explore the different tradeoffs. We will present concrete results for native prover-verifier runtimes, as well as benchmarks and estimates for proof composition with the verifier encoded as a halo2 circuit.</p><hr><p>Author: Marcin Górny</p><p>Thank you Antonio Mejías Gil & Giacomo Fenzi for helpful comments and discussions.</p></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=../../>Home</a></li><li><a href=../../about>About</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#lasso-overview>Lasso overview</a><ul><li><a href=#motivation-for-lookups>Motivation for lookups</a></li><li><a href=#enter-the-lookup-table>Enter the lookup (table)</a></li><li><a href=#lasso-in-a-nutshell>Lasso in a nutshell</a></li><li><a href=#idk-how-it-works-but-i-know-why-its-expensive>IDK how it works, but I know why it’s expensive,</a></li></ul></li><li><a href=#what-should-i-aim-for>What should I aim for?</a></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&text=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&is_video=false&description=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt&body=Check out this article: https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&title=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&name=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt&description=Problem%20statement%20In%20this%20write-up%2c%20we%20aim%20to%20provide%20context%20for%20the%20Need%20for%20Speed%3a%20why%20do%20we%20need%20efficient%20%28multilinear%29%20polynomial%20commitment%20schemes%20for%20lookups%2c%20specifically%20in%20the%20context%20of%20Lasso%20and%20Jolt.%0aTo%20put%20the%20problem%20into%20context%2c%20we%20first%20motivate%20the%20need%20for%20Lasso%2c%20and%20lookups%20in%20general%2c%20with%20an%20example.%20We%20then%20briefly%20describe%20the%20non-trivial%20marriage%20of%20lookup%20arguments%20with%20general%20SNARKs%20for%20R1CS.%20To%20complete%20the%20big%20picture%2c%20we%20provide%20a%20short%20introduction%20to%20Lasso%e2%80%99s%20solution%20to%20lookups%20-%20and%20where%20exactly%20the%20polynomial%20commitment%20schemes%20come%20up." aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHungryCatsStudio.github.io%2fposts%2flookups-ml-pcs%2f&t=Need%20for%20Speed%3a%20efficient%20multilinear%20PCS%20in%20Lasso%20and%20Jolt" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2023 Hungry Cats Studio</div><div class=footer-right><nav><ul><li><a href=../../>Home</a></li><li><a href=../../about>About</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=../../lib/font-awesome/css/all.min.css><script src=../../lib/jquery/jquery.min.js></script><script src=../../js/main.js></script><script src=../../js/code-copy.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>